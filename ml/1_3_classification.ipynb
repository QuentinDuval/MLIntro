{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Categories of models\n",
    "---\n",
    "\n",
    "In terms of outputs, there are several board categories of approaches to the problem of classification:\n",
    "\n",
    "1. **Discriminative**: just return the classification of the input\n",
    "2. **Probabilistic Discriminative**: return a probability mass over the possible classifications\n",
    "3. **Probabilistic generative**: return a model for the data generation process, which can be used for classification\n",
    "\n",
    "The discriminative functions are arguably not useful enough as we lack the confidence of the model for the prediction. Such models will in effect create a decision boundary, and points will change from one category to the other in a non-smooth way.\n",
    "\n",
    "The **probabilistic models** in general solves the issue of the first category by providing us with a smooth transition from one class to another. We can also use the returned probability mass $p(\\mathcal{C}_k|x)$ to feed a **utility function** that allows to take more **rational decisions**.\n",
    "\n",
    "The **generative models** go further and give us a generic model $p(x|\\mathcal{C}_k)$. This model can be useful to generate new inputs for other processes (for instances generating images of cats). There are also usually **more stable** because they model **forward probabilities** $p(x|\\mathcal{C}_k)$, the probablity that the cause is creating the effect. If the *a priori* probability $p(\\mathcal{C}_k)$ changes, they will not be affected.\n",
    "\n",
    "The counterpart is that they generally need a considerable amount of parameters to tune. But this is might be considerably more work to do, and might not be interesting if you only care about classification (see **GANS** for interesting parallels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Probabilistic models\n",
    "---\n",
    "\n",
    "Parts that are common to both generative and discriminative probabilistic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### The origin of Softmax\n",
    "\n",
    "The softmax function is a way to get **smooth version of max** which is pretty handy for models that use gradient descent and therefore require a chain smooth functions from the input to the output:\n",
    "\n",
    "&emsp; $\\displaystyle \\operatorname{softmax}(x_1 \\dots x_n) = (y_1 \\dots y_n)$\n",
    "&emsp; where\n",
    "&emsp; $\\displaystyle y_i = \\frac{\\exp x_i}{\\sum_j \\exp x_j}$\n",
    "\n",
    "The softmax function is also sound from a probabilitic perspective. It originates from linear models and is the Bayes' theorem under the assumption that the data is generated using a mixture of gaussian distributions with the same covariance matrix.\n",
    "\n",
    "&emsp; $\\displaystyle p(x|\\mathcal{C}_k) = \\mathcal{N}(\\mu_k, \\Sigma)$\n",
    "&emsp; \n",
    "&emsp; $\\displaystyle p(C_k|x) = \\frac{p(x|C_k)p(C_k)}{\\sum_i p(x|C_i)p(C_i)}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle \\boxed{p(C_k|x) = \\frac{exp(a_k)}{\\sum_i exp(a_i)}}$\n",
    "&emsp; where\n",
    "&emsp; $a_k = w_k^T x$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Proof**: We start by matching $\\exp(a_k) = p(x|C_k) p(C_k)$ and unroll the computation:\n",
    "\n",
    "&emsp; $\\displaystyle a_k = \\log p(C_k) - \\frac{D}{2} \\log 2 \\pi - \\frac{1}{2} \\log |\\Sigma| -\\frac{1}{2}(x - \\mu_k)^T \\Sigma^{-1} (x - \\mu_k)$\n",
    "\n",
    "&emsp; $\\displaystyle a_k = \\log p(C_k) - \\frac{D}{2} \\log 2 \\pi - \\frac{1}{2} \\log |\\Sigma| -\\frac{1}{2} \\big(x^T \\Sigma^{-1} x + \\mu_k^T \\Sigma^{-1} \\mu_k - 2 x^T \\Sigma^{-1} \\mu_k \\big)$\n",
    "\n",
    "We can simplify the terms by removing the common part between all $a_i$ (as they cancel out thanks to the ratio):\n",
    "\n",
    "&emsp; $\\displaystyle a_k = \\log p(C_k) - \\frac{1}{2} \\big(\\mu_k^T \\Sigma^{-1} \\mu_k - 2 \\mu_k^T \\Sigma^{-1} x \\big)$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $a_k = w_k^T x + b_k$\n",
    "&emsp; (affine form in $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### The origin of Sigmoid\n",
    "\n",
    "The sigmoid is a **smooth version of a step function** from 0 to 1. For binary classification, this is the smooth equivalent of a yes-no decision. As for softmax, the smoothness is handy for gradient descent:\n",
    "\n",
    "&emsp; $\\displaystyle \\operatorname{sigmoid}(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{1 + e^x}$\n",
    "\n",
    "As for softmax, this function has a sound probabilistic meaning. It corresponds to the Bayes' theorem under the assumption that the data is generated using a mixture of 2 gaussians with the same covariance matrix:\n",
    "\n",
    "&emsp; $\\displaystyle p(x|\\mathcal{C}_k) = \\mathcal{N}(\\mu_k, \\Sigma)$\n",
    "&emsp; \n",
    "&emsp; $\\displaystyle p(C_1|x) = \\frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1) + p(x|C_2)p(C_2)}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle \\boxed{p(C_1|x) = \\frac{1}{1 + e^{-y}}}$\n",
    "&emsp; where\n",
    "&emsp; $y = w_k^T x$\n",
    "\n",
    "**Proof**: We re-write the Bayes' theorem to make appear the ratio of posterior between the two classes:\n",
    "\n",
    "&emsp; $\\displaystyle p(C_1|x) = \\frac{1}{1 + \\frac{p(x|C_2)p(C_2)}{p(x|C_1)p(C_1)}}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle p(C_1|x) = \\frac{1}{1 + e^{-y}}$\n",
    "&emsp; where\n",
    "&emsp; $\\displaystyle y = \\log \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$\n",
    "\n",
    "We then unroll the expression of $y$, and using the fact that the covariance matrix $\\Sigma$ we get:\n",
    "\n",
    "&emsp; $\\displaystyle y = \\log \\frac{p(C_1)}{p(C_2)} + \\frac{1}{2} \\mu_2^T \\Sigma^{-1} \\mu_2 - \\frac{1}{2} \\mu_1^T \\Sigma^{-1} \\mu_1 + (\\mu_1 - \\mu_2)^T \\Sigma^{-1} x$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $y = w^T x + b_k$\n",
    "&emsp; (affine form in $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Single linear decision boundary\n",
    "\n",
    "As shown above, under the assumption that the generative process is a mixture of gaussians $p(C_k|x)$, all gaussians having identical covariance matrices, a simple linear boundary (an hyperplan in general) will be enough to separate the classes.\n",
    "\n",
    "For two classes and one dimensional inputs, this line can be found by hand:\n",
    "\n",
    "&emsp; $\\displaystyle p(C_1|x) = \\frac{1}{1 + e^{-y}} = 0.5 \\implies e^{-y} = 1 \\implies y = 0$\n",
    "\n",
    "If we further assume that both class prior probabilities are equal $p(C_1) = p(C_2)$, we get:\n",
    "\n",
    "&emsp; $\\displaystyle (\\mu_2 - \\mu_1) x = \\frac{1}{2}(\\mu_2^2 - \\mu_1^2) = \\frac{1}{2}(\\mu_2 - \\mu_1)(\\mu_2 + \\mu_1)$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle x = \\frac{\\mu_1 + \\mu_2}{2}$\n",
    "\n",
    "The best decision binary between two values pertubated by noise is precisely in the middle of them if both values are equally likely to be send a priori. This has obvious implications when decoding messages sent over a noisy channel (one of the problem Shannon was interested in) under the assumption that the entropy of the message sent is maximized (that is, if both symbols have the same probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Multiple linear decision boundaries\n",
    "\n",
    "Similarly, when there are multiple classes, the decision boundary between two class can be found by searching for the points where the probabilities $p(C_i|x) = p(C_j|x)$. These are the points where $a_i = a_j$ in the softmax:\n",
    "\n",
    "&emsp; $\\displaystyle p(C_k|x) = \\frac{exp(a_k)}{\\sum_i exp(a_i)}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $p(C_i|x) = p(C_j|x) \\iff a_i = a_j \\iff w_i^T x = w_j^T x \\iff (w_i - w_j)^T x$\n",
    "\n",
    "This decision boundary is the equation of an hyperplane, separating the regions where $\\forall i, j : w_i^T x \\ge w_j^T x$. The overall decision boundaries, once assembled all together can form much more complex patterns. Note the efficiency of the approach: with $N$ outputs, we can separate $N$ classes by creating ${N \\choose 2} = \\frac{1}{2}N(N+1)$ boundaries (one for each pair of classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.array([\n",
    "    [1, 2, 1],\n",
    "    [3, 0, 2],\n",
    "    [0, -3, -4],\n",
    "    [3, -4, 3]])\n",
    "\n",
    "points = np.array([[x, y] for x in np.arange(-5, 4, 0.1) for y in np.arange(-3, 3, 0.1)])\n",
    "classes = np.zeros(points.shape[0])\n",
    "for i, (x, y) in enumerate(points):\n",
    "    classes[i] = np.array([np.dot([x, y, 1], w) for w in weights]).argmax()\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "for c_id, color in (0, 'blue'), (1, 'green'), (2, 'red'), (3, 'orange'):\n",
    "    ax.scatter(points[classes==c_id][:,0], points[classes==c_id][:,1], color=color, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Non-linear decision boundaries\n",
    "\n",
    "The moment we drop the assumption that the data generative process is a mixture of gaussian with equal covariance matrices, the linearity of the decision boundaries does not hold anymore. In practice, the simplest generative models will not have the same covariance matrices for each mixture, and for the more complex generative models, the distribution will not be gaussian and will likely have multiple modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show round decision boundaries with different covariance matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
