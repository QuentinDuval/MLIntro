{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Differentials, Gradients, Level Curves, Hessian, Jacobians\n",
    "---\n",
    "\n",
    "Lots of examples below are given for a function of 2 variables, but are easily extended for any number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Partial derivatives\n",
    "\n",
    "We define the partial derivative of a function $f(x,y)$ with respect to $x$ as the limit of the slope of change of $f$ when we modify $x$ by $dx$:\n",
    "\n",
    "&emsp; $\\displaystyle \\frac{\\partial f}{\\partial x} = \\underset{h \\rightarrow \\infty}{lim} \\frac{f(x+h,y)}{h}$\n",
    "&emsp; and\n",
    "&emsp; $\\displaystyle \\frac{\\partial f}{\\partial y} = \\underset{h \\rightarrow \\infty}{lim} \\frac{f(x,y+h)}{h}$\n",
    "\n",
    "Intuitively, we can think of it as \"small change of $f$ over small change of $x$\", but this intuition is also really confusing when it comes to thinking \"how small is the change\". It helps to keep in mind that the formal definition is about limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Differentials\n",
    "\n",
    "We define the differential of $f(x)$, as **the linear function that best approximate** $f(x+dx) - f(x)$ in the neighborhood of $x$:\n",
    "\n",
    "&emsp; $\\boxed{df = df(x,dx) = \\sum \\frac{\\partial f}{\\partial x_i} dx_i = dx^T \\nabla f(x) = \\langle \\nabla f(x), dx \\rangle}$\n",
    "&emsp; where\n",
    "&emsp; $\\nabla f$ is the gradient defined after\n",
    "\n",
    "Directions $dx$ along which the differential is null define a plan whose equation is $df(x,dx) = 0$. This is the plan along which variations of $f$ are null. For instance, for a function of two arguments $f(x,y)$, the equation of the plan is:\n",
    "\n",
    "&emsp; $\\displaystyle df = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy = 0$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $df = 0$ defines a plan whose normal is $\\displaystyle \\big (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\big )$\n",
    "\n",
    "Similarly, $f(x) + df(x, dx)$ actually describes the **equation of a plan tangent to $f$ at the point $x$**:\n",
    "\n",
    "&emsp; $\\displaystyle df = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy + f(x, y) = z$\n",
    "&emsp; which is a plan whose normal is\n",
    "&emsp; $\\displaystyle \\big (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, -1 \\big )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Gradient\n",
    "\n",
    "Consider the function $f(x,y)$, we define the gradient of $f$ as:\n",
    "\n",
    "&emsp; $\\boxed{ \\nabla f = \\big ( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\big ) }$\n",
    "&emsp; which is a vector holding the **partial derivatives of $f$** with respect to each of its inputs variables\n",
    "\n",
    "The gradient as several interesting properties, which offer different point of views on it:\n",
    "\n",
    "1. We have $df = \\nabla f . dx \\implies $ the change of $f$ along direction $u$ is $\\nabla f . u$\n",
    "2. The gradient is **orthogonal to the level curves of $f$** (level are curves are such that $df=0$)\n",
    "3. The gradient gives the **direction along which the value of $f$ changes the fastest** (thee steepest ascent)\n",
    "\n",
    "Property (3) can be seen from property (1): the dot product between two vectors $u$ and $v$ is equal to $\\Vert u \\Vert \\Vert v \\Vert \\cos \\theta$, where $\\theta$ is the angle formed in the plan spanned by both vectors $u$ and $v$. The dot product and is therefore maximized when $\\theta = 0$, that is when the two vectors are colinear and pointing in the same direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Jacobian\n",
    "\n",
    "Say the function $f$ has $N$ inputs and $M$ outputs. We can see it as a collection of functions $f_1$ to $f_M$, each of which produces a component (the value of one dimension). The Jacobian is defined as a matrix where **each row contains the gradient of one of the component**:\n",
    "\n",
    "&emsp; $\\displaystyle J = \\begin{pmatrix} \\nabla f_1 \\\\ \\vdots \\\\ \\nabla f_M \\end{pmatrix}$\n",
    "&emsp; or \n",
    "&emsp; $\\displaystyle J = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\dots & \\frac{\\partial f_1}{\\partial x_N} \\\\ \\vdots & & \\vdots \\\\ \\frac{\\partial f_M}{\\partial x_1} & \\dots & \\frac{\\partial f_M}{\\partial x_N} \\end{pmatrix}$\n",
    "\n",
    "To compute the differentials along each dimensions, and similarly was what we did for the gradient, we multiply the Jacobian matrix with a vector $dx = (dx_1, \\dots dx_N)^T$ containing the differentials of the inputs:\n",
    "\n",
    "&emsp; $\\displaystyle \\begin{pmatrix} df_1 \\\\ \\vdots \\\\ df_M \\end{pmatrix} = \\begin{pmatrix} \\nabla f_1 . dx \\\\ \\vdots \\\\ \\nabla f_M . dx \\end{pmatrix} = \\begin{pmatrix} \\nabla f_1 \\\\ \\vdots \\\\ \\nabla f_M \\end{pmatrix} \\begin{pmatrix} dx_1 \\\\ \\vdots \\\\ dx_N \\end{pmatrix} = J \\; dx$\n",
    "\n",
    "Note that the Jacobian has properties that are similar to the gradient: the level curves are replaced by the **null space (or kernel)** of the Jacobian, defined by all the vector $u$ such that: $J u = 0$. This equation is similar to the **orthogonality property** of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Hessian matrix\n",
    "\n",
    "The Hessian matrix is the Jacobian of the gradient of $f$. Indeed, the gradient can be seen as a function with multiple components: the partial derivatives of $f$ along each of its input dimensions. The Hessian matrix is therefore equal to:\n",
    "\n",
    "&emsp; $\\displaystyle H = \\nabla \\nabla f = \\begin{pmatrix} \\frac{\\partial^2 f}{\\partial x_1 \\partial x_1} & \\dots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_N} \\\\ \\vdots & & \\vdots \\\\ \\frac{\\partial^2 f}{\\partial x_N \\partial x_1} & \\dots & \\frac{\\partial^2 f}{\\partial x_N \\partial x_N} \\end{pmatrix}$\n",
    "&emsp; which is a symmetric matrix since $\\displaystyle \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_i}$\n",
    "\n",
    "The \"definite-ness\" of the Hessian matrix allows to identify whether a critical point $\\nabla f = 0$ is:\n",
    "\n",
    "* a local minimum: $H$ is positive definite, i.e. $x^T H x \\ge 0, \\forall x$\n",
    "* a local maximum: $H$ is negative definite, i.e. $x^T H x \\le 0, \\forall x$\n",
    "* a saddle point otherwise\n",
    "\n",
    "Since the Hessian is symmetric, it has real eigenvalues, and we can evaluate its \"definite-ness\" by looking at the sign of these eigenvalues. If they are all positive, the matrix is positive definite. If they are all negative, the matrix is negative definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "If we consider a function $f(x,y)$, where $x(u,v)$ and $y(u,v)$ are themselves functions, we can compute the variations of $f$ with respect to $u$ and $v$ by using the chain rule:\n",
    "\n",
    "&emsp; $\\displaystyle \\frac{\\partial f}{\\partial u} = \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial u} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial u}$\n",
    "&emsp; and\n",
    "&emsp; $\\displaystyle \\frac{\\partial f}{\\partial v} = \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial v} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial v}$\n",
    "\n",
    "The chain rule follows from the definition of differentials, if we just replace $dx$ and $dy$ by their definition and keep the terms of the component we are interested about, for instance $du$ if we are interested in the partial derivative with respect to $u$:\n",
    "\n",
    "&emsp; $\\displaystyle df = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy$\n",
    "&emsp; with \n",
    "&emsp; $\\displaystyle dx = \\frac{\\partial x}{\\partial u} du + \\frac{\\partial x}{\\partial v} dv$\n",
    "&emsp; and \n",
    "&emsp; $\\displaystyle dy = \\frac{\\partial y}{\\partial u} du + \\frac{\\partial y}{\\partial v} dv$\n",
    "\n",
    "The chain rule can be written more generically as:\n",
    "\n",
    "&emsp; $\\boxed{\\frac{\\partial f}{\\partial y_j} = \\sum_i \\frac{\\partial f}{\\partial x_i} \\frac{\\partial x_i}{\\partial y_j}}$\n",
    "&emsp; where $x_i$ are the input variable of $f$ that depends on $y_j$\n",
    "\n",
    "We see from the indices that it ressembles matrix multiplication. It can indeed be re-written as a **product between the gradient of $f$ with respect to $x$ and the Jacobian of $x$ with respect to $y$**:\n",
    "\n",
    "&emsp; $\\displaystyle \\nabla_{y} f = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1} & \\dots & \\frac{\\partial f}{\\partial x_M} \\end{pmatrix} \\begin{pmatrix} \\frac{\\partial x_1}{\\partial y_1} & \\dots & \\frac{\\partial x_1}{\\partial y_N} \\\\ \\vdots & & \\vdots \\\\ \\frac{\\partial x_M}{\\partial y_1} & \\dots & \\frac{\\partial x_M}{\\partial y_N} \\end{pmatrix}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\boxed{\\nabla_{y} f = (\\nabla_x f)^T J_y(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Product and quotient rule\n",
    "\n",
    "As specific application of the chain rule, we can derive the **product rule**:\n",
    "\n",
    "&emsp; $\\displaystyle \\frac{d \\big( u(x) v(x)\\big)}{dx} = \\frac{\\partial \\big(u(x) v(x) \\big)}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial \\big(u(x) v(x) \\big)}{\\partial v} \\frac{\\partial v}{\\partial x}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\boxed{(uv)' = u'v + v'u}$\n",
    "\n",
    "Similarly, we can derive the **quotient rule**:\n",
    "\n",
    "&emsp; $\\displaystyle \\frac{d}{dx} \\Big( \\frac{u(x)}{v(x)} \\Big) = \\frac{\\partial}{\\partial u} \\Big( \\frac{u(x)}{v(x)} \\Big) \\frac{\\partial u}{\\partial x} + \\frac{\\partial}{\\partial v} \\Big( \\frac{u(x)}{v(x)} \\Big) \\frac{\\partial v}{\\partial x}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\boxed{\\Big(\\frac{u}{v} \\Big)' = \\frac{u' v - v' u}{v^2}}$\n",
    "\n",
    "These rules are applicable for multivariable functions as well:\n",
    "\n",
    "&emsp; $\\displaystyle \\forall i, \\frac{\\partial u(x) v(x)}{\\partial x_i} = \\frac{\\partial u(x)}{\\partial x_i} v(x) + u(x) \\frac{\\partial v(x)}{\\partial x_i}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\boxed{\\nabla (uv) = \\nabla u \\times v + u \\times \\nabla v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Taylors expansion\n",
    "\n",
    "The Taylor expansion for a **single variable function** $f(x)$ in the neighborhood of $a$:\n",
    "\n",
    "&emsp; $\\displaystyle f(x) = \\sum_{n=0}^{\\infty} {\\frac{f^{(n)}(a)}{n!}}(x-a)^n$\n",
    "&emsp; where\n",
    "&emsp; $f^{(n)}$ is the $n^{th}$ derivative of $f$\n",
    "\n",
    "**Proof:** Recursively match each order, by first matching the value of the function, then the value of the derivative, then the value of the second derivative, and so on... The factorials naturally appears as the result of differentiating a polynomial:\n",
    "\n",
    "&emsp; $\\displaystyle f^{(0)}(x) = \\sum_{n=0}^{\\infty} b_n (x-a)^n$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $f(a) = b_0$\n",
    "\n",
    "&emsp; $\\displaystyle f^{(1)}(x) = \\sum_{n=1}^{\\infty} n b_n (x-a)^{n-1}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $f^{(1)}(a) = 1 \\times b_1$\n",
    "\n",
    "&emsp; $\\displaystyle f^{(2)}(x) = \\sum_{n=2}^{\\infty} n (n-1) b_n (x-a)^{n-2}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $f^{(2)}(a) = 2 \\times 1 \\times b_2$\n",
    "\n",
    "&emsp; $\\displaystyle f^{(3)}(x) = \\sum_{n=3}^{\\infty} n (n-1) (n-2) b_n (x-a)^{n-3}$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $f^{(3)}(a) = 3 \\times 2 \\times 1 \\times b_3$\n",
    "\n",
    "&emsp; $\\dots$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Taylors expansion (multivariate)\n",
    "\n",
    "The Taylor expansion for a **multi variable function** $f(x)$ in the neighborhood of $a$:\n",
    "\n",
    "&emsp; $\\displaystyle f(x) = \\sum_{|\\alpha| = 0}^{\\infty} {\\frac {D^\\alpha f(a)}{|\\alpha|!}}(x-a)^{\\alpha}$\n",
    "&emsp; where\n",
    "&emsp; $|\\alpha| = \\sum_n \\alpha_i$\n",
    "&emsp; and\n",
    "&emsp; $D^{\\alpha} f = \\frac {\\partial^{|\\alpha|} f}{\\partial x_1^{\\alpha_1} \\cdots \\partial x_n^{\\alpha_n}}$\n",
    "\n",
    "The Taylor expansion at order 2 is better known in terms of the gradient and the Hessian matrix:\n",
    "\n",
    "&emsp; $\\displaystyle f(x) \\simeq f(a) + (x - a)^T \\nabla f + (x - a)^T H (x-a)$\n",
    "\n",
    "This formula also helps to understand why we need to check the \"definite-ness\" of the Hessian in order to check if a critical point is a local minimum, a local maximum, or a saddle point. Indeed, if the gradient is null, the Hessian determines in which direction $f(x)$ will move in the neighborhood of $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Optimization with equality constraints\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Optimization with one constraint\n",
    "\n",
    "Consider minimizing / maximizing the function $f(x)$ constraint to $g(x) = 0$. The critical points $x_0$ we are looking for are the ones where $\\nabla f(x_0) = \\lambda \\nabla g(x_0)$ with $\\lambda \\ne 0$.\n",
    "\n",
    "> **Proof:** Consider the level curves of $f(x) = c$. At a critical point $x_0$, this level curve must be tangent to the level curve $g(x) = 0$, or otherwise we could move along the curve $g(x) = 0$ to find a better value for $f$. The tangent of a level curve is the gradient of the function, and so $\\nabla f$ must be colinear to $\\nabla g$.\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = f(x) - \\lambda g(x)$\n",
    "&emsp; ,\n",
    "&emsp; $\\nabla_x \\mathcal{L} = 0 \\implies \\nabla f(x) = \\lambda \\nabla g(x)$\n",
    "&emsp; and \n",
    "&emsp; $\\displaystyle \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = 0 \\implies g(x) = 0$\n",
    "\n",
    "Searching for the critical points of the langrangian will give us potential solutions to our problem (we still have to check for their values to check if they are valid maximum of minimums)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Optimization with multiple constraints\n",
    "\n",
    "Consider minimizing / maximizing the function $f(x)$ constraint to $g_1(x) = 0, \\dots g_n(x) = 0$. The critical points $x_0$ we are looking for are the ones where $\\nabla f(x_0) = \\lambda_1 \\nabla g_1(x_0) + \\dots + \\lambda_n \\nabla g_n(x)$ such that $\\exists i, \\lambda_i \\ne 0$.\n",
    "\n",
    "Similarly as above, we can build a lagrangian and look for its critical points in order to solve the constraint problem:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = f(x) - \\sum_i \\lambda_i g_i(x)$\n",
    "&emsp; such that\n",
    "&emsp; $\\exists i, \\lambda_i \\ne 0$\n",
    "\n",
    "**Proof:** Consider the $G(x) = 0$, where $G(x) = (g_1(x), \\dots g_n(x))$ is a manifold because the $g_i$ are smooth. If $f(x_0)$ changes along the manifold $G$ in the neighborhood of $x_0$, then $x_0$ cannot be a critical point, or otherwise we could move along $G$ to find a better spot.\n",
    "\n",
    "To stay in the plan, any move in the direction $u$ from $x_0$ must be such that $G$ stays constant. And for $x_0$ to be a critical point, any move in the direction of $u$ should not change $f$ either. This translates elequantly in terms of Jacobian and Gradients:\n",
    "\n",
    "&emsp; $\\displaystyle \\begin{pmatrix} dg_1 \\\\ \\vdots \\\\ dg_n \\end{pmatrix} = \\begin{pmatrix} \\nabla g_1 . dx \\\\ \\vdots \\\\ \\nabla g_n . dx \\end{pmatrix} = J_G \\; dx = 0$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\nabla f^T dx = 0$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\begin{pmatrix} \\nabla f . dx \\\\ \\vdots \\\\ \\nabla f . dx \\end{pmatrix} = F \\; dx = 0$\n",
    "\n",
    "So the kernel (a.k.a. null space) of $J_G$ is contained in the kernel of $F$. So the space spanned by $F$ is contained in the space spanned by $J_G$. So the basis of the row space of $F$ which is $\\nabla f$ is expressible as a linear combination of the basis of the row space of of $J_G$ and we have:\n",
    "\n",
    "&emsp; $\\displaystyle \\nabla f = \\sum_n \\lambda_i \\nabla g_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Example: deriving properties through Lagrangian\n",
    "\n",
    "Lagrangians and Lagrange multipliers ($\\lambda_i$) can be used to solve optimization problems in closed forms. They can also be used to derive some interesting properties between quantities.\n",
    "\n",
    "For instance, say we have a covariance matrix $S$ and we are looking for directions, that is unit vectors $v$ (the constraint is on the norm) such that the quantity $v^T S v$ is maximized (such that the variance in that direction is maximized). We can build a Lagrangian for this:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda) = x^T S x - \\lambda ( x^T x - 1 )$\n",
    "&emsp; and\n",
    "&emsp; $\\nabla_x \\mathcal{L} = 0$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $S x = \\lambda x$\n",
    "\n",
    "We therefore show that vectors that satisfy this are eigen vectors of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Optimization with inequality constraints\n",
    "---\n",
    "\n",
    "When things are not symmetric (minimizing is not the same as maximizing) anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Maximization with one inequality constraint\n",
    "\n",
    "Consider **maximizing** the function $f(x)$ constraint to $g(x) \\ge 0$. The critical points $x_0$ are such that:\n",
    "\n",
    "* $\\nabla f(x_0) = - \\lambda \\nabla g(x_0)$ with $\\lambda \\ge 0$\n",
    "* $\\lambda \\ne 0$ if and only if $g(x_0) = 0$\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\boxed{\\mathcal{L}(x,\\lambda) = f(x) + \\lambda g(x)}$ with $\\lambda \\ge 0$\n",
    "\n",
    "**Proof:** For $g(x_0) = 0$, consider the level curves of $f(x) = c$. At a critical point $x_0$, this level curve must be tangent to the level curve $g(x) = 0$, but must also be such that $\\nabla f$ point toward the forbidden region, i.e $g(x) < 0$, toward the descending $g$. It means that $\\nabla f$ must be colinear and point to the other direction of $\\nabla g$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Minimization with one inequality constraint\n",
    "\n",
    "Consider **minimizing** the function $f(x)$ constraint to $g(x) \\ge 0$. The critical points $x_0$ are such that:\n",
    "\n",
    "* $\\nabla f(x_0) = \\lambda \\nabla g(x_0)$ with $\\lambda \\ge 0$\n",
    "* $\\lambda \\ne 0$ if and only if $g(x_0) = 0$\n",
    "\n",
    "We can therefore create a function $\\mathcal{L}$ for Lagrangian, that combines $f$ and $g$ such that its critical points encapsulate the optimization objective:\n",
    "\n",
    "&emsp; $\\boxed{\\mathcal{L}(x,\\lambda) = f(x) - \\lambda g(x)}$ with $\\lambda \\ge 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### General case (multiple constraints of different types)\n",
    "\n",
    "To **maximize** the function $f(x)$ subject to the constraints $g_i(x) = 0$ and $h_j(x) \\ge 0$, find the critical points of the Lagrangian:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda,\\mu) = f(x) + \\sum_i \\lambda_i g_i(x) + \\sum_i \\mu_i h_i(x)$\n",
    "&emsp; with\n",
    "&emsp; $\\lambda_i \\ne 0$\n",
    "&emsp; and\n",
    "&emsp; $\\mu_j \\ge 0$\n",
    "\n",
    "To **minimize** the function $f(x)$ subject to the constraints $g_i(x) = 0$ and $h_j(x) \\ge 0$, find the critical points of the Lagrangian:\n",
    "\n",
    "&emsp; $\\mathcal{L}(x,\\lambda,\\mu) = f(x) - \\sum_i \\lambda_i g_i(x) - \\sum_i \\mu_i h_i(x)$\n",
    "&emsp; with\n",
    "&emsp; $\\lambda_i \\ne 0$\n",
    "&emsp; and\n",
    "&emsp; $\\mu_j \\ge 0$\n",
    "\n",
    "**The simple mnemonic is + for maximization and - for minimization** and make the constraints on the factors positive when dealing with inequality constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
