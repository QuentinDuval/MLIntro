{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Game forms\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Normal form\n",
    "\n",
    "Represent the game as a matrix (for 2 players) where each pure-strategy (for one-stage game, the strategy is just a single action) appears on the side of the matrix and the payoff for each pair of player-strategy is shown in the cells, separated with a slash:\n",
    "\n",
    "<div style=\"width:80%\">\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Prisonner's dilema</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>D</th>\n",
    "            <th>S</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>-4/-4</td>\n",
    "            <td>0/-5</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>S</th>\n",
    "            <td>-5/0</td>\n",
    "            <td>-1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Matching pennies</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>A</th>\n",
    "            <td>1/-1</td>\n",
    "            <td>-1/1</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>B</th>\n",
    "            <td>-1/1</td>\n",
    "            <td>1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:right;\">\n",
    "        <div style=\"text-align:center\">Battle of sexes</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>O</th>\n",
    "            <th>F</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>O</th>\n",
    "            <td>2/1</td>\n",
    "            <td>0/0</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>F</th>\n",
    "            <td>0/0</td>\n",
    "            <td>1/2</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "In the prisonner's dilemna, **D** is the denouce option and **S** is the silence option:\n",
    "\n",
    "* If both player denouce each other, they get 4 years in prison each\n",
    "* If one of them denouces the other, he gets out and the other one gets 5 years in prison.\n",
    "* If they both keep silent, they get limited time in prison.\n",
    "\n",
    "The matching pennies example is such that the player 1 wins if both action matches and loses otherwise. Compared to the prisonner dilema, this is a non-cooperation game in which one of the two player must lose (like Chess). The Battle of Sexes is a cooperation game in which both player want to go the same place, either **O** for opera or **F** for football club, but both have different preferences for opera or football.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Extended form\n",
    "\n",
    "The extended form of a game is a **game tree** representation of a game particularly useful when the game is made of several stages, or when the actions are sequential and not simultaneous.\n",
    "\n",
    "* Each node in the circle corresponds to a player choice of move (or a chance node if chance is involved)\n",
    "* Each leaf correspond to a payoff (the cumulative result at the end of the game)\n",
    "* Labels along the edges represent the actions performed by the players\n",
    "* Dash lines between node represent uncertainty about which of the states we are in\n",
    "\n",
    "![title](img/ExtendedForm.png)\n",
    "\n",
    "An **information set** is information available to a player at a given stage of the game to make its decision for the next action. A singleton information set contains the exact identifier of the node (the player has knowledge about the past). Dash lines represent uncertainty about the state and correspond to information set with several state identifiers inside them.\n",
    "\n",
    "Erasing information about past move allows **simultaneous moves** games encoded as extended forms, while preserving the state information allows to represent **sequential move** games.\n",
    "\n",
    "*Note: For each extended form, there is an equivalent unique normal form (where each strategy on the side is the path in the game tree), but not the other way around.*\n",
    "\n",
    "<br>\n",
    "\n",
    "### Types of games\n",
    "\n",
    "A **perfect information game** is a game in which the extended form does not contain any uncertainly regarding the information set (each player knows the past) and does not contain any chance node. Games that do not fulfil these requirements are called **imperfect information games**.\n",
    "\n",
    "**Static game** are games in which the actions of the players does not influence the actions of the other player. Typically, these are one-stage games with simulatenous moves like the ones shown above. **Dynamic games** are multi-stage games in which the actions are not the same depending on the past (exemple of Chess, Go). These games are necessarily partially sequential.\n",
    "\n",
    "**Multi stage games** are games composed of a series of independent sub-games (for instance, playing prisoner's dilema followed by matching pennies). **Repeated games** are multi-stage games where we repeat the same sub-game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# One-stage simultaneous games\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Stategy and Mixed Strategy\n",
    "\n",
    " A **pure strategy** for a game is a function that returns the action to play for each information set. A **mixed strategy** is a distribution of probability over a selection of pure strategy. A **behavioral strategy** is a function that returns a probability distribution of actions to play for each information set. It turns out that mixed strategies and behavioral strategies are mostly equivalent: we can always represent one with the other.\n",
    "\n",
    "The **Pareto Optimum** of a game is the combination of strategy that would lead to the best outcome for both players. For instance in the prisoner dilema is the stay silent for both player. Unfortunately, strategies that lead to this optimum do not necessarily correspond to what players would play because the best interest solution does not entail the general overal good.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dominance and Best response\n",
    "\n",
    "A **strictly dominated** strategy is such that another strategy is stricly better whatever what the opponents play. A player should never play a strictly dominated strategy, at least in single stage games (we will see later for multi-stage games). Eliminated recursively strictly dominated strategies can sometimes lead to a single resulting pure strategy:\n",
    "\n",
    "<div style=\"width:80%\">\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>C</th>\n",
    "            <td>4/2</td>\n",
    "            <td>5/3</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>5/4</td>\n",
    "            <td>6/0</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th><strike>&nbsp;C&nbsp;</strike></th>\n",
    "            <td><strike>4/2</strike></td>\n",
    "            <td><strike>5/3</strike></td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>5/4</td>\n",
    "            <td>6/0</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:right;\">\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th><strike>&nbsp;B&nbsp;</strike></th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th><strike>&nbsp;C&nbsp;</strike></th>\n",
    "            <td><strike>4/2</strike></td>\n",
    "            <td><strike>5/3</strike></td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>5/4</td>\n",
    "            <td><strike>6/0</strike></td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "A **best response** to the opponent strategy is a strategy that is equal or better in payoff. After removing all the strictly dominated, the remaining strategies are always the best response to another strategy.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Pure strategy Nash equilibrium\n",
    "\n",
    "A nash equilibrium corresponds to a pair of strategies that are **stable**:\n",
    "\n",
    "* if player 1 believes that player 2 will play his move then player 1 has no better response\n",
    "* if player 2 believes that player 1 will play his move then player 2 has no better response\n",
    "\n",
    "There might be one pure strategy nash equilibrium (D-D for Prisoner's Dilema), several pure strategy nash equilibriums (O-O or F-F for the Battle of Sexes) or no pure strategy nash equilibrium (in matching pennies):\n",
    "\n",
    "<div style=\"width:80%\">\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Prisonner's dilema</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>D</th>\n",
    "            <th>S</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td><b>-4/-4</b></td>\n",
    "            <td>0/-5</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>S</th>\n",
    "            <td>-5/0</td>\n",
    "            <td>-1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Matching pennies</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>A</th>\n",
    "            <td>1/-1</td>\n",
    "            <td>-1/1</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>B</th>\n",
    "            <td>-1/1</td>\n",
    "            <td>1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:right;\">\n",
    "        <div style=\"text-align:center\">Battle of sexes</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>O</th>\n",
    "            <th>F</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>O</th>\n",
    "            <td><b>2/1</b></td>\n",
    "            <td>0/0</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>F</th>\n",
    "            <td>0/0</td>\n",
    "            <td><b>1/2</b></td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "Nash equilibrium correspond to a **stable pair of strategies** in the sense that **no player would like to deviate from his strategy if his belief of the opponent player the matching strategy is correct**. And they are quite easy to find: for each player look at the best possible action for each of the opponent strategy (look for the maximum payoff) and see when they match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Mixed Nash equilibrium\n",
    "\n",
    "For some games, there are **mixed strategies Nash equilibrium**. For instance, in the matching pennies game, if we note $p$ and $q$ the probability of player 1 and 2 to play move $A$, then $(p=\\frac{1}{2}, q=\\frac{1}{2})$ is a mixed nash equilibrium:\n",
    "\n",
    "* player 1 would not benefit from increasing or decreasing $p$\n",
    "* player 2 would not benefit from increasing or decreasing $q$\n",
    "\n",
    "Note that if either $p$ or $q$ would not be equal to one half, then the other player would have benefits in playing a pure strategy instead. The way to find mixed nash equilibriums here is therefore to solve for $p$ and $q$ to be such that playing A or B is indifferent for both player A and B: indeed **the only reason to mix strategies is if they both have the same payoff**.\n",
    "\n",
    "In general, we should look for combinations of move such that each move as the same expected payoff under the belief that the other player will play a given strategy or mixed strategy.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Nash equilibrium vs Pareto optimum\n",
    "\n",
    "A **stable position does not mean that the outcome is the best for both players** (the pareto optimum). For instance, in the prisoner's dilema, the nash equilibrium is when both player denouce each other. Indeed, any other position is unstable:\n",
    "\n",
    "* if both are silent, one of them could benefit from talking\n",
    "* if one is talking, the other should start talking as well\n",
    "\n",
    "If you think that this does not represent reality, it is either because the payoff do not represent your true values (not betraying your partners) or because you think in terms of a repeated game in which you are accountable for your bad actions and this might erode the trusts people have in you: in repeated games, it becomes possible to play something else than a Nash equilibrium.\n",
    "\n",
    "Similarly, a **mixed nash equilibrium does not necessarily have a better payoff than a pure-one**: for instance in Battle of the Sexes, the mixed Nash equilibrium would have a payoff of 1/1, which is less than the payoff of 2/1 or 1/2.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Continuous actions examples\n",
    "\n",
    "The Nash equilibrium also works for continuous actions, both for pure strategies and mixed strategies. For instance, we can play a game in which two companies fight for profit on the market by controlling their production $q_1$ and $q_2$:\n",
    "\n",
    "* The demand determines the price $p = 100 - q_1 - q_2$\n",
    "* The marginal cost (cost of each new article) is $c$\n",
    "\n",
    "Each company wants to increase their own benefit $b_1$ and $b_2$ as much as possible. But the more they product, the lower the price of the goods, so they want to maximize the following quantities (which depend on the opponent production):\n",
    "\n",
    "&emsp; $b_1(q_1|q_2) = (100 - q_1 - q_2) \\, q_1 - c \\, q_1 \\implies \\nabla b_1 = 100 - 2 q_1 - q_2 - c = 0$\n",
    "\n",
    "&emsp; $b_2(q_2|q_1) = (100 - q_1 - q_2) \\, q_2 - c \\, q_2 \\implies \\nabla b_2 = 100 - q_1 - 2 q_2 - c = 0$\n",
    "\n",
    "From which we get: $\\displaystyle q_1 = q_2 = \\frac{100 - c}{3}$. For a cost of 10, this means producing 30 pieces each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Solving sequential perfect information games\n",
    "---\n",
    "\n",
    "When moves are no more simultaneous be sequential, no chance is involved, and each player remember each move has been taken (that is, all players know the current state of the game perfectly).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sub-game perfect Nash equilibrium\n",
    "\n",
    "A **sub-game** is a sub-tree of the extensive form that is independent: it is not linked by any dash lines that represent unknown information set to another sub-tree. For perfect information games, each sub-tree of the game tree is a sub-game.\n",
    "\n",
    "A **pure strategy** still consists in a function that maps each information set (each position, each configuration in the game tree) to an action, while a **behavioral strategy** maps each information set to a probability distributions on the possible moves.\n",
    "\n",
    "A sub-game perfect Nash equilibrium is a pair of strategies such that both players have no benefits in deviating form this strategy **at any information set**. This is different from a Nash equilibrium for which both players would have no benefits in deviating from the strategy on the **equilibrium path** (the path that leads to the outcome).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Backward induction\n",
    "\n",
    "The general idea to find such sub-game perfect Nash equilibrium for such games is that we can handle each sub-game separately by estimating the gain of the sub-games from the smallest to the biggest, in a process called as **backward induction** (or dynamic programming from programming perspective).\n",
    "\n",
    "For each sub-game, we replace the sub-game by the expected pay-off of the Nash equilibrum at the upper level (the surrounding sub-game) and bubble up this information until we reach the top. One interesting thing about perfect information game is that there is always one such equilibrium, and there is exactly one if none of the payoffs at the leaves are equal.\n",
    "\n",
    "For zero sum games (or fixed sum payoff games), the backward induction shown below is totally equivalent to the **minimax algorithm**. Techniques such as alpha-beta pruning can be used to solve these games efficiently, and cut-offs and heuristics can be used to handle game trees that are too deep.\n",
    "\n",
    "For games with non-fixed payoff sum, we actually need to bubble up the payoff of both players, and each player is only interested in maximizing his own payoff.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Pareto optimum, knowledge and order of play\n",
    "\n",
    "The order of play does not change the fact that Nash equilibrium do not necessarily correspond to the **pareto optimum**. For instance, in the Centipede game below, the players will never reach 3/3 and stop at 1/1 or 1/2:\n",
    "\n",
    "![title](img/centipede_game.svg)\n",
    "\n",
    "The sequencing of move can also unbalance some games to the point of making them much less interesting:\n",
    "\n",
    "* Matching pennies: the second player will always win\n",
    "* Battle of sexes: the first player will always get his/her preferred outcome\n",
    "\n",
    "The main change with sequential games is that the **belief of the other's strategy becomes a knowledge**. Player 2 knows the previous move of player 1, and player 1 can more easily understand what player 2 will do after its move as well.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Continuous action example\n",
    "\n",
    "If we go back to the game in which two companies fight for profit on the market by controlling their production $q_1$ and $q_2$, the game is now significantly changed because player 1 can move first and its move is known to player 2.\n",
    "\n",
    "Player 1 will maximize its benefit $b_1$, by looking in the future at what will be the price fixed by $q_2$. To do so, player 1 has to compute first what would be the optimal choice of play of player 2 depending on its information set (the quantity $q_1$ here):\n",
    "\n",
    "&emsp; $\\displaystyle b_2(q_2|q_1) = (100 - q_1 - q_2) \\, q_2 - c \\, q_2 \\implies \\nabla b_2 = 100 - q_1 - 2 q_2 - c = 0 \\implies q_2 = \\frac{100 - q_1 - c}{2}$\n",
    "\n",
    "Now player 1 can just maximize its benefits, based on the knowledge of this sub-strategy. Its benefit is therefore not conditioned on $q_2$ anymore because it can be replaced by anticipated value:\n",
    "\n",
    "&emsp; $\\displaystyle b_1(q_1) = (100 - q_1 - \\frac{100 - q_1 - c}{2}) \\, q_1 - c \\, q_1 \\implies \\nabla b_1 = 50 - q_1 - \\frac{c}{2} = 0 \\implies q_1 = \\frac{100 - c}{2}$\n",
    "\n",
    "For a cost of 10, it means producing 45 units for player 1 and 22.5 for player 2. As we can see, the results are completely different from playing the game simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Sequential imperfect information games\n",
    "---\n",
    "\n",
    "Some games will mix the sequential and simultaneous game phases and are therefore imperfection information game (because some nodes have multiple information sets), as this game based on the Cuba crisis:\n",
    "\n",
    "* The player 1 (US) can escalate to oppose the missiles in Cuba or ignore the threat\n",
    "* The player 2 (USSR) can backdown faced to escalation or confront the US\n",
    "* At this points, both player can nuke or retreat: if any one nukes, the world is doomed\n",
    "\n",
    "![title](img/mutual_destruction.svg)\n",
    "\n",
    "\n",
    "This process of backward induction does not work quite the same as for perfect information games, minimax for instance is not applicable, as we need some kind of belief on what the opponent would do when moves are simultaneous. Once the belief is fixed, we can follow the backward induction process by starting from the end of the extended form:\n",
    "\n",
    "<table style=\"text-align:center;width:250px;margin-left:100px;margin-right:100px\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Retreat</th>\n",
    "    <th>Nuke</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Retreat</th>\n",
    "    <td>-5/-5</td>\n",
    "    <td>-100/-100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Nuke</th>\n",
    "    <td>-100/-100</td>\n",
    "    <td>-100/-100</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The first Nash equilibrium here is mutual destruction (Nuke/Nuke), and so we can bubble up that information, to get the following simplified game in which we see that the player 1 should escalate and blocade Cuba:\n",
    "\n",
    "![title](img/mutual_destruction_2.svg)\n",
    "\n",
    "The second Nash equilibrium is mutual retreat. If the player 1 believes that this will be the outcome of the last game, he should ignore the threat and let the player 2 put the missiles on Cuba. **The two belief leads to two different outcomes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Multi-stage / repeated games\n",
    "---\n",
    "\n",
    "When multiple game are played one after the other by the same players, the situation gets more interesting.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Types of games\n",
    "\n",
    "**Multi-stage** games are games made of independent **stage games** where each player gets to remember the outcomes (what was played and the payoffs) of the previous stage games. **Repeated** games are multi-stage games where the same stage game is repeated multiple times. **Infinite** games are games in which neither parties knows exactly when it will stop: for each stage game, there is a chance $0 \\le \\delta < 1$ that it will be followed by another stage game.\n",
    "\n",
    "The goal for these games is to maximize the **net present value** of the stream of payoffs:\n",
    "\n",
    "&emsp; $\\displaystyle NPV = \\sum_k \\delta^k v_k$\n",
    "&emsp; where $\\delta$ is the discounting factor and $v_k$ is the payoff at stage *k*\n",
    "\n",
    "For finite games, the discounting factor can be equal to 1. For infinite games it must be lower than 1 for the series to converge, and it essentially corresponds to the expected value of the payoff where $\\delta$ is the probability to continue.\n",
    "\n",
    "<br>\n",
    "\n",
    "### One-stage unimprovable\n",
    "\n",
    "Because each stage game can be seen as a sub-game in an extended form, we use the same concept of **sub game perfect equilibria** presented before. One such trivial sub-game perfect equilibria for the repeated game is to play a Nash equilibrium at each stage game (treated each game independently).\n",
    "\n",
    "To identify other equilibrium, we use the **one-stage deviation principle**: if no player is able to modify its sequence of play at one stage such that its overall strategy is improved, then the strategy is a sub-game perfect equilibrium.\n",
    "\n",
    "> **Proof**: if the sequence of play $s_1 \\dots s_N$ is improvable, let $s_1 \\dots s_k$ be the longest path made of improvable stage-game strategy (all stage-games later are not improvable). If we consider the rest of the sequence $s_k \\dots s_N$, this sequence is such that only the stage-game *k* is improvable. Thus, if not stage-game is improvable, the whole sequence is not improvable either.\n",
    "\n",
    "In particular, this principle imposes that **we should always play by a nash equilibrium at the last stage game**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Finite multi-stage games solutions\n",
    "\n",
    "For the last stage game, we know we must play a Nash equilibrium. But if there are two Nash equilibriums at the end, with different payoffs, we can use these to *bargain* a strategy made of stage-game strategies that are not Nash equilibrium. We play the best Nash equilibrium in case of cooperation, and reverse to the worse Nash equilibrium otherwise:\n",
    "\n",
    "* the *carrot* is the Nash equilibrium with the highest payoff\n",
    "* the *stick* is the Nash equilibrium with the lowest payoff\n",
    "\n",
    "For this to work, the **discounting factor must be high enough to have a strong incentive to cooperate**. This discounting factor is a measure of the **accountability / reputation** of each player and forces them to play nice.\n",
    "\n",
    "Here is one example for two Prisonner's dilema stage-games followed by a game with 2 nash equilibrium:\n",
    "\n",
    "<div style=\"width:80%\">\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Prisonner's dilema</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>D</th>\n",
    "            <th>S</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>-4/-4</td>\n",
    "            <td>0/-5</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>S</th>\n",
    "            <td>-5/0</td>\n",
    "            <td>-1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:left;\">\n",
    "        <div style=\"text-align:center\">Prisonner's dilema</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>D</th>\n",
    "            <th>S</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>D</th>\n",
    "            <td>-4/-4</td>\n",
    "            <td>0/-5</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>S</th>\n",
    "            <td>-5/0</td>\n",
    "            <td>-1/-1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width:33%;float:right;\">\n",
    "        <div style=\"text-align:center\">Two nash game</div>\n",
    "        <table style=\"text-align:center;width:150px;margin-left:auto;margin-right:auto\">\n",
    "          <tr>\n",
    "            <th></th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>A</th>\n",
    "            <td>4/4</td>\n",
    "            <td>0/0</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <th>B</th>\n",
    "            <td>0/0</td>\n",
    "            <td>1/1</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "A sub-game perfect Nash equilibrium could be that both player stay silent for the two prisonners dilema, then play the 4/4 Nash equilibrium. If one of them defects, they denouce the other player and play the 1/1 Nash equilibrium. We can check if there are any possible positive deviations from this:\n",
    "\n",
    "* For the first prisonner's dilema, treason would benefit 1 but cost $3 \\, (\\delta + \\delta^2)$\n",
    "* For the second prisonner's dilema, treason would benefit 1 but cost $3 \\, \\delta$\n",
    "* Playing 4/4 in case of treason would bring the whole deal down and cost $3 \\, (1 + \\delta)$ for a benefit of $3 \\, \\delta^2$\n",
    "\n",
    "So if $\\delta \\ge \\frac{1}{3}$, there is no one-deviation that leads to a better result so this is a sub-game perfect equilibrium. Note that this would not work for a fixed number of prisonner's dilema in a row for there is but one Nash equilibrium at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Infinite repeated games solutions\n",
    "\n",
    "If a game is infinite, it creates a kind of artificial additional equilibrium that can be used to bargain, even in case of stage-game with a single Nash equilibrium. This additional equilibrium is often based on the concept of **grim-trigger**: at first defection, go back to the non-cooperative game forever.\n",
    "\n",
    "For instance, in an infinite prisonner's dilema, each player could play silent but go back to denounce at the first defection. The infinite payoff in case of cooperation would be better than defecting at any point $N$:\n",
    "\n",
    "&emsp; $\\displaystyle v_N(S) = \\sum_{k=N}^{\\infty} \\delta^k (-1) = \\frac{-\\delta^N}{1 - \\delta}$\n",
    "&emsp; versus\n",
    "&emsp; $\\displaystyle v_N(D) = \\sum_{k=N+1}^{\\infty} \\delta^k (-4) = \\frac{-4 \\delta^{N+1}}{1 - \\delta}$\n",
    "\n",
    "&emsp; $\\displaystyle v_N(D) \\ge v_N(S) \\implies -4 \\delta^{N+1} \\ge -\\delta^N \\implies 4 \\delta \\le 1 \\implies \\delta \\le \\frac{1}{4}$\n",
    "\n",
    "So if the chance of the two players to meet again is higher than 25%, then they should cooperate.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Folk's Theorem\n",
    "\n",
    "For a stage-game whose payoffs are $(p_1 \\dots p_N)$, a point $p^*$ in the convex hull of these payoffs is a **feasable average payoff** for a series of an infinite game of this stage-game, given that the discount factor is close enough to 1:\n",
    "\n",
    "&emsp; $p^* = \\sum_n \\alpha_n p_n$\n",
    "&emsp; where\n",
    "&emsp; $\\sum_n \\alpha_n = 1$\n",
    "&emsp; and\n",
    "&emsp; $\\forall n, \\alpha_n \\ge 0$\n",
    "\n",
    "For instance, in the prisoner's dilema, the convex hull, the point (-2, -2) is inside it, and so we can find a sub-game perfect equilibria that leads to this solution: alternate between S/S and D/D for each player, and default to D/D at the first defection:\n",
    "\n",
    "![title](img/convex_hull.svg)\n",
    "\n",
    "Similarly, we can find a strategy based on alterning S/D and D/S or any other strategy that leads to a outcome that is better than the repetition of the Nash Equilibrium D/D, given that the discount rate is sufficiently close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Appendix: graphs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/mutual_destruction.svg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.graphviz.org/doc/info/attrs.html#d:sep\n",
    "from graphviz import Digraph\n",
    "\n",
    "node_attr = dict(fontsize='10', height='0.1')\n",
    "arr_attr = dict(fontsize='10', arrowsize='0.6')\n",
    "\n",
    "dot = Digraph(comment='Assured mutual destruction')\n",
    "dot.attr(pad='0.1', ranksep='0.3', nodesep='0.6', fontsize='6', imagescale='200')\n",
    "\n",
    "dot.node('x0', '1', shape='circle', **node_attr)\n",
    "with dot.subgraph() as s:\n",
    "    s.node('y1', '2', shape='circle', **node_attr)\n",
    "    s.node('y2', '0/0', shape='rectangle', **node_attr)\n",
    "dot.node('x3', '10/-10', shape='rectangle', **node_attr)\n",
    "dot.node('x4', '1', shape='circle', **node_attr)\n",
    "dot.node('y5', '2', shape='circle', **node_attr)\n",
    "dot.node('y6', '2', shape='circle', **node_attr)\n",
    "dot.node('l1', '-5/-5', shape='rectangle', **node_attr)\n",
    "dot.node('l2', '-100/-100', shape='rectangle', **node_attr)\n",
    "dot.node('l3', '-100/-100', shape='rectangle', **node_attr)\n",
    "dot.node('l4', '-100/-100', shape='rectangle', **node_attr)\n",
    "\n",
    "dot.edge('x0', 'y1', xlabel='escalate', **arr_attr)\n",
    "dot.edge('x0', 'y2', label='ignore', **arr_attr)\n",
    "dot.edge('y1', 'x3', xlabel='backdown', **arr_attr)\n",
    "dot.edge('y1', 'x4', label='confront', **arr_attr)\n",
    "dot.edge('x4', 'y5', xlabel='retreat', **arr_attr)\n",
    "dot.edge('x4', 'y6', label='nuke', **arr_attr)\n",
    "dot.edge('y5', 'l1', label='retreat', **arr_attr)\n",
    "dot.edge('y5', 'l2', label='nuke', **arr_attr)\n",
    "dot.edge('y6', 'l3', label='retreat', **arr_attr)\n",
    "dot.edge('y6', 'l4', label='nuke', **arr_attr)\n",
    "\n",
    "dot.edge('y5', 'y6', arrowhead='none', style='dashed', constraint='false')\n",
    "\n",
    "dot.format='svg'\n",
    "dot.render('img/mutual_destruction', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/mutual_destruction_2.svg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_attr = dict(fontsize='10', height='0.1')\n",
    "arr_attr = dict(fontsize='10', arrowsize='0.6')\n",
    "\n",
    "dot = Digraph(comment='Assured mutual destruction')\n",
    "dot.attr(pad='0.1', ranksep='0.3', nodesep='0.6', fontsize='6', imagescale='200')\n",
    "\n",
    "dot.node('x0', '1', shape='circle', **node_attr)\n",
    "dot.node('y1', '2', shape='circle', **node_attr)\n",
    "dot.node('y2', '0/0', shape='rectangle', **node_attr)\n",
    "dot.node('x3', '10/-10', shape='rectangle', **node_attr)\n",
    "dot.node('x4', '-100/-100', shape='rectangle', **node_attr)\n",
    "\n",
    "dot.edge('x0', 'y1', xlabel='escalate', **arr_attr)\n",
    "dot.edge('x0', 'y2', label='ignore', **arr_attr)\n",
    "dot.edge('y1', 'x3', xlabel='backdown', **arr_attr)\n",
    "dot.edge('y1', 'x4', label='confront', **arr_attr)\n",
    "\n",
    "dot.format='svg'\n",
    "dot.render('img/mutual_destruction_2', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/centipede_game.svg'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_attr = dict(fontsize='10', height='0.1')\n",
    "arr_attr = dict(fontsize='10', arrowsize='0.6')\n",
    "\n",
    "dot = Digraph(comment='Centipede game')\n",
    "dot.attr(pad='0.1', ranksep='0.3', nodesep='0.6', imagescale='200')\n",
    "\n",
    "dot.node('x0', '1', shape='circle', **node_attr)\n",
    "dot.node('x1', '2', shape='circle', **node_attr)\n",
    "dot.node('x2', '1', shape='circle', **node_attr)\n",
    "dot.node('x3', '2', shape='circle', **node_attr)\n",
    "\n",
    "dot.node('y0', '1/1', shape='rectangle', **node_attr)\n",
    "dot.node('y1', '1/2', shape='rectangle', **node_attr)\n",
    "dot.node('y2', '3/1', shape='rectangle', **node_attr)\n",
    "dot.node('y3', '1/4', shape='rectangle', **node_attr)\n",
    "dot.node('y4', '3/3', shape='rectangle', **node_attr)\n",
    "\n",
    "dot.edge('x0', 'y0', **arr_attr)\n",
    "dot.edge('x1', 'y1', **arr_attr)\n",
    "dot.edge('x2', 'y2', **arr_attr)\n",
    "dot.edge('x3', 'y3', **arr_attr)\n",
    "dot.edge('x3', 'y4', constraint='false', **arr_attr)\n",
    "\n",
    "dot.edge('x0', 'x1', constraint='false', **arr_attr)\n",
    "dot.edge('x1', 'x2', constraint='false', **arr_attr)\n",
    "dot.edge('x2', 'x3', constraint='false', **arr_attr)\n",
    "\n",
    "dot.format='svg'\n",
    "dot.render('img/centipede_game', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.fill_between(\n",
    "    [-5, -4, -1, 0],\n",
    "    [0, -4, -5+1/4, -5],\n",
    "    [0, -1/4, -1, -5],\n",
    "    alpha=0.2)\n",
    "plt.scatter([-2], [-2], color='green', s=100, marker='o')\n",
    "plt.plot([-3.9, -1.1], [-3.9, -1.1], color='green', alpha=0.5)\n",
    "plt.scatter([-5, -4, -1, 0], [0, -4, -1, -5], color='orange', s=60)\n",
    "plt.scatter([-4], [-4], color='orange', s=250, alpha=0.5)\n",
    "plt.ylim(-6, 1)\n",
    "plt.xlim(-6, 1)\n",
    "plt.savefig('img/convex_hull.svg', format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
