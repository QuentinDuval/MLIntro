{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Univariate Gaussian\n",
    "---\n",
    "\n",
    "The formula for a univariate Gaussian (or normal) distribution:\n",
    "\n",
    "&emsp; $\\boxed{\\mathcal{N}(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{\\textstyle - \\frac{(x-\\mu)^2}{2 \\sigma^2}}}$\n",
    "&emsp; where\n",
    "&emsp; $\\mathbb{E}[x] = \\mu$\n",
    "&emsp; and\n",
    "&emsp; $\\mathbb{V}[x] = \\sigma^2$\n",
    "\n",
    "Knowing the mean and variance of a gaussian distribution is enough to completely characterize the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Indefinite integral\n",
    "\n",
    "The gaussian distribution **does not have an indifinite integral**. We can still compute the square of its integral, and this is how we find the normalizing constant. To evaluate the integral of $e^{-x^2}$, we use a multivariate gaussian with 2 variables:\n",
    "\n",
    "&emsp; $\\displaystyle I = \\int_{-\\infty}^{\\infty} e^{-x^2} dx = 2 \\int_0^{\\infty} e^{-x^2} dx$\n",
    "&emsp; $\\implies$\n",
    "&emsp; $\\displaystyle I^2 = 4 \\int_{-\\infty}^{\\infty} e^{-x^2} dx \\int_{-\\infty}^{\\infty} e^{-y^2} dy = 4 \\int_0^{\\infty} \\Bigg( \\int_0^{\\infty} e^{-x^2(1 + \\frac{y^2}{x^2})} dy \\Bigg) dx$\n",
    "\n",
    "We then do the change of variables $s = \\frac{y}{x}$ which implies $dy = x \\, ds$:\n",
    "\n",
    "&emsp; $\\displaystyle I^2 = 4 \\int_0^{\\infty} \\Bigg( \\int_0^{\\infty} e^{-x^2(1 + s^2)} x ds \\Bigg) dx = 4 \\int_0^{\\infty} \\Bigg( \\int_0^{\\infty} \\frac{-2 x (1 + s^2)}{- 2(1 + s^2)} e^{-x^2(1 + s^2)} dx \\Bigg) ds$\n",
    "\n",
    "&emsp; $\\displaystyle I^2 = 4 \\int_0^{\\infty} \\Big[ \\frac{1}{- 2(1 + s^2)} e^{-x^2(1 + s^2)} \\Big]_{x=0}^{x=\\infty} ds = 4 \\int_0^{\\infty} \\frac{1}{2(1 + s^2)} ds = 2 \\Big[ \\arctan s \\Big]_{s=0}^{s=\\infty} = \\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Moments\n",
    "\n",
    "The p-moment of a distribution is defined as the expected value of functions $x \\mapsto x^p$. The central p-moments of a distribution are defined as the expected value of functions $x \\mapsto (x-\\mu)^p$. Because the distribution is symmetric, the central moments are zero for even values of $p$.\n",
    "\n",
    "&emsp; $\\mathbb{E}[x] = \\mu$ (first moment)\n",
    "\n",
    "&emsp; $\\mathbb{E}[x^2] = \\mu^2 + \\sigma^2$ (second moment)\n",
    "\n",
    "&emsp; $\\mathbb{E}[(x-\\mu)^2] = \\sigma^2 = \\mathbb{V}[x]$ (central second moment, the variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exponential distribution\n",
    "\n",
    "The exponential distribution is part of the exponential distributions, of the form:\n",
    "\n",
    "&emsp; $\\displaystyle p(x|\\theta) = h(x) \\, g(\\theta ) \\, \\exp \\big( \\eta (\\theta )\\cdot T(x) \\big)$\n",
    "\n",
    "Where the parameters $\\theta = (\\mu, \\sigma^2)$ and we have the following (not unique) decomposition:\n",
    "\n",
    "&emsp; $T(x) = \\begin{pmatrix} 1 \\\\ x \\\\ x^2 \\end{pmatrix}$\n",
    "&emsp; $\\eta(\\theta) = \\begin{pmatrix} -\\mu^2 / (2 \\sigma^2) \\\\ \\mu / \\sigma^2 \\\\ - 1 / (2 \\sigma^2) \\end{pmatrix}$\n",
    "&emsp; $\\displaystyle h(x) = \\frac{1}{\\sqrt{2 \\pi}}$\n",
    "&emsp; $\\displaystyle g(\\theta) = \\frac{1}{\\sqrt{\\sigma^2}}$\n",
    "\n",
    "So if we have an exponential, with inside it an **order 2 polynomial in x**, we get a Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Maximizing entropy\n",
    "\n",
    "The Gaussian distribution maximizes the differential entropy **for a given mean and variance**:\n",
    "\n",
    "&emsp; $\\displaystyle h(p) = - \\int_{-\\infty}^{\\infty} p(x) \\log p(x) \\, dx$\n",
    "\n",
    "To prove it, we consider the KL divergence between any other distribution $f$ and the normal distribution $g$ and use the property that the KL divergence is always positive:\n",
    "\n",
    "&emsp; $\\displaystyle D_{KL}(f||g) = - \\int f(x) \\log \\frac{g(x)}{f(x)} dx = - h(f) - \\int f(x) \\big( \\log \\frac{1}{\\sqrt {2 \\pi \\sigma^2}} - \\frac{(x-\\mu)^2}{2 \\sigma^2} \\big) dx$\n",
    "\n",
    "&emsp; $\\displaystyle D_{KL}(f||g) = - h(f) + \\frac{1}{2} \\log (2 \\pi \\sigma^2) + \\frac{1}{2 \\sigma^2} \\int f(x) (x-\\mu)^2 dx$\n",
    "\n",
    "&emsp; $\\displaystyle D_{KL}(f||g) = - h(f) + \\frac{1}{2} \\log (2 \\pi \\sigma^2) + \\frac{\\sigma^2}{2 \\sigma^2} = -h(f) + h(g) \\ge 0$\n",
    "\n",
    "Where the differential entropy of the gaussian distribution is:\n",
    "\n",
    "&emsp; $\\displaystyle h(p) = - \\int_{-\\infty}^{\\infty} p(x) \\log p(x) \\, dx = \\log (\\sigma \\sqrt{2 \\pi}) + \\frac{1}{2} = \\frac{1}{2} \\log ( 2 \\pi \\sigma^2 ) + \\frac{1}{2}$\n",
    "&emsp; (see [this link](https://proofwiki.org/wiki/Differential_Entropy_of_Gaussian_Distribution))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Multivariate Gaussian\n",
    "---\n",
    "\n",
    "* slicing\n",
    "* not the same as conditional gaussian\n",
    "* laws of deductions\n",
    "* PCA to find the axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Multiple data points\n",
    "---\n",
    "\n",
    "* independence => covariance matrix of the form $\\alpha^{-1} I_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Conjugate priors\n",
    "---\n",
    "\n",
    "* todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
